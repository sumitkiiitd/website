<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sumit Kumar</title>
  
  <meta name="author" content="Sumit Kumar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sumit Kumar</name></br>
                Learning with machines.<br>
              </p>
              <p>I am a PhD student in <a target=”_blank” href="https://cse.iiitd.ac.in/">CSE </a> department at <a target=”_blank” href="https://iiitd.ac.in/">IIIT Delhi </a> working under <a target=”_blank” href="https://faculty.iiitd.ac.in/~rinku/">Dr. Rinku Shah</a>. I'm majorly interested in Systems, Networking and Cloud.
              </p>
              <p>
                Previously, I worked under the guidance of <a target=”_blank” href="https://jnu.ac.in/content/karan">Dr. Karan Singh</a> in the Network Security Lab, <a target=”_blank” href="https://jnu.ac.in/node">Jawaharlal Nehru University, New Delhi</a> where I have worked on the Energy Optimization of Wireless Sensor Nodes for my M.Tech degree. Earlier, I have also completed my M.Sc. in Computer Science from <a target=”_blank” href="https://www.cusb.ac.in/">Central University of South Bihar, Gaya</a>. I graduated from Magadh University with a Bachelor's degree in Computer Application. 
              </p>
              <p>
                My prior research experience has been on networking, WSN and applied machine learning.
              </p>
              <p style="text-align:center">
                <a target=”_blank” href="mailto:sumitk@iiitd.ac.in">Email</a> &nbsp/&nbsp
                <a target=”_blank” href="data/Sumit_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a target=”_blank” href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a target=”_blank” href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a target=”_blank” href="https://www.linkedin.com/in/sumit-kumaar/">Linkedin</a> &nbsp/&nbsp
                <!--<a target=”_blank” href="https://twitter.com/sumit0966">Twitter</a> &nbsp/&nbsp-->
                <a target=”_blank” href="https://github.com/sumitkiiitd">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a target=”_blank” href="images/Sumit.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Sumit_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Updates</heading>
              <p>
                <b>[Dec '23]:</b> Volunteer and Participant at the <a target=”_blank” href="https://www.iiitd.ac.in/fsn/">ACM India Winter School on "Full-stack Networking (FSN)"</a>. <a target=”_blank” href="https://github.com/pnl-iiitd/acm_fsn/blob/main/Day_1_Linux_networking_basics/Dec18_handson_session.pdf">[Presentation]</a></br>
                <b>[Oct '23]:</b> Started my Ph.D. journey under the supervision of <a target=”_blank” href="https://faculty.iiitd.ac.in/~rinku/">Dr. Rinku Shah</a>.</br>
                <b>[Mar '23]:</b> Joined as Intern at CNH Industrial in the Data Analytics team.</br> 
                
                <!--
                <b>[Nov '21]:</b> Presented <i>AudViSum</i> at BMVC 2021! <a target=”_blank” href="https://www.youtube.com/watch?v=Hier-zMWcc0">[Presentation]</a> </br> 
                <b>[Oct '21]:</b> <i>AudViSum</i> accepted at BMVC 2021! </br> 
                <b>[Sep '21]:</b> Presented <i>Listen to the Pixels</i> at ICIP 2021! <a target=”_blank” href="https://www.youtube.com/watch?v=xUwzSQaQ9oQ">[Presentation]</a> </br> 
                <b>[May '21]:</b> <i>Listen to the Pixels</i> accepted at ICIP 2021! </br>
                <b>[Jan '21]:</b> Presented <i>CardioGAN</i> at ICPR 2020! <a target=”_blank” href="hhttps://www.youtube.com/watch?v=BmOG9IMXFUU">[Presentation]</a> </br> 
              -->
              </p>
            </td>
          </tr>
        </tbody></table>

        <!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <script>
          function myFunction(pub_name) {
              var x = document.getElementById(pub_name);
              if (x.style.display === 'none') {
                  x.style.display = 'block';
              } else {
                  x.style.display = 'none';
              }
        }
        </script>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a target=”_blank” href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a target=”_blank” href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
              <a target=”_blank” href="https://phogzone.com/">Peter Hedman</a>,
              <a target=”_blank” href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a target=”_blank” href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
              <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a target=”_blank” href="http://jonbarron.info/mipnerf">project page</a>
              /
              <a target=”_blank” href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a target=”_blank” href="https://youtu.be/EpH175PY1A0">video</a>
              /
              <a target=”_blank” href="https://github.com/google/mipnerf">code</a>
              <p></p>
              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
            </td>
          </tr>  -->
<!--
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/adverb.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/adverb.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.html">
              <papertitle>AdVerb: Visually Guided Audio Dereverberation</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://schowdhury671.github.io/">Sanjoy Chowdhury</a>, 
              <a target=”_blank” href="https://sreyan88.github.io/">Sreyan Ghosh</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://anton-jeran.github.io/antonjeran.github.io/">Anton Ratnarajah</a>,
              <a target=”_blank” href="https://utkarsh4430.github.io/">Utkarsh Tyagi</a>,
              <a target=”_blank” href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>
              <br>
              <em>ICCV</em>, 2023 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--             <a target=”_blank” href="#">Code</a>
              /
              <a target=”_blank” href="https://schowdhury671.github.io/adverb/">Website</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('iccv23_0_bib')">BibTex</a>
              <p></p>
              <p>AdVerb leverages visual cues of the environment to estimate clean audio from reverberant audio.
                For instance, given a reverberant sound produced in a large hall, our model attempts to remove the 
                reverb effect to predict the anechoic or clean audio.</p>
              <div id="iccv23_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @article{chowdhury2023adverb,<br>
                    title={AdVerb: Visually Guided Audio Dereverberation},<br>
                    author={Chowdhury, Sanjoy and Ghosh, Sreyan and Subhrajyoti, Dasgupta and Ratnarajah, Anton and Tyagi, Utkarsh and Manocha, Dinesh},<br>
                    journal={ICCV},<br>
                    year={2023}<br>
                  }
              </font></div>
            </td>
          </tr>

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/unshadownet.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/unshadownet.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://ieeexplore.ieee.org/document/10217820">
              <papertitle>UnShadowNet: Illumination Critic Guided Contrastive Learning for Shadow Removal</papertitle>
              </a>
              <br>
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=W8DTl_gAAAAJ&hl=en">Arindam Das</a>, 
              <a target=”_blank” href="https://scholar.google.com/citations?user=z0a8rsYAAAAJ&hl=en">Senthil Yogamani</a>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=aH6w8VcAAAAJ&hl=en">Ciarán Eising</a>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=HTfERCsAAAAJ&hl=en">Andrei Bursuc</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>IEEE Access</em> 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--              <a target=”_blank” href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10217820">Paper</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('ieeeaccess_0_bib')">BibTex</a>
              <p></p>
              <p>Shadow removal is a hard task given the challenges associated with it, one of them being unavailabilty of paired 
                labelled data. We propose a weakly supervised, illumination critic guided method using contrastive learning for 
                efficiently removing shadows.
              </p>
              <div id="ieeeaccess_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                @article{dasgupta2023unshadownet,</br>
                  title={UnShadowNet: Illumination Critic Guided Contrastive Learning For Shadow Removal},</br>
                  author={Dasgupta, Subhrajyoti and Das, Arindam and Yogamani, Senthil and Das, Sudip and Eising, Ciar{\'a}n and Bursuc, Andrei and Bhattacharya, Ujjwal},</br>
                  journal={IEEE Access},</br>
                  year={2023},</br>
                  publisher={IEEE}</br>
                }
              </font></div>
            </td>
          </tr>
          
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/audvisum.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/audvisum.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">
              <papertitle>AudViSum: Self-Supervised Deep Reinforcement Learning for diverse Audio-Visual Summary generation</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>, 
              <a target=”_blank” href="https://scholar.google.com/citations?user=FcEMgBgAAAAJ&hl=en">Aditya P. Patra</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>BMVC</em>, 2021 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--              <a target=”_blank” href="https://github.com/schowdhury671/AudViSum">Code</a>
              /
              <a target=”_blank” href="https://www.youtube.com/watch?v=Hier-zMWcc0">Presentation</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('bmvc21_0_bib')">BibTex</a>
              <p></p>
              <p>Generating representative and diverse audio-visual summaries by exploiting both the audio and visual modalities, unlike prior works. Also presented a new dataset on TVSum and OVP with audio and visual annotations.</p>
              <div id="bmvc21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @inproceedings{chowdhury2021audvisum, </br>
                    title={AudViSum: Self-Supervised Deep Reinforcement Learning for Diverse Audio-Visual Summary Generation.}, </br>
                    author={Chowdhury, Sanjoy and Patra, Aditya P. and Dasgupta, Subhrajyoti and Bhattacharya, Ujjwal},</br>
                    booktitle={BMVC},</br>
                    <!-- pages={245},</br> -->
<!--                    year={2021}</br>
                  }
              </font></div>
            </td>
          </tr>



          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/icip_21.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/icip_21.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }
                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").show();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://ieeexplore.ieee.org/document/9506019">
                <papertitle>Listen to the Pixels</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>ICIP</em>, 2021
              <br>
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/audio_visual_cosegmentation">Code</a> /
              <a target=”_blank” href="https://www.youtube.com/watch?v=xUwzSQaQ9oQ">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icip21_0_bib')">BibTex</a>
              <p></p>
              <p>Audio-visual co-segmentation and sound source separation using a novel multimodal fusion mechanism, also addressing partially occluded sound source separation and co-segmentation for multiple but similar sound sources.
              </p>
              <div id="icip21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9506019,</br>
                    author={Chowdhury, Sanjoy and Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},</br>
                    booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, </br>
                    title={Listen To The Pixels}, </br>
                    year={2021},</br>
                    pages={2568-2572},</br>
                    doi={10.1109/ICIP42928.2021.9506019}</br>
                  }
              </font></div>
            </td>
          </tr> 


          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cardiogan.png' width="160"></div>
                <img src='images/cardiogan.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").fadeToggle();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9412905">
                <papertitle>CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms</papertitle>
              </a>
              <br>
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>ICPR</em>, 2020
              <br>
              <a target=”_blank” href="https://www.youtube.com/watch?v=BmOG9IMXFUU">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icpr20_0_bib')">BibTex</a>
              <p></p>
              <p>
                Generating synthetic ECGs, for easy sharing without risk of privacy breach, using an Attention-based Generative Adversarial Network.
              </p>
              <div id="icpr20_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:   #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9412905,<br> 
                    author={Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},<br>
                    booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, <br>
                    title={CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms}, <br>
                    year={2021},<br>
                    pages={3193-3200},<br>
                    doi={10.1109/ICPR48806.2021.9412905}<br>
                }
            </td>
          </tr> 


          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/devanagari.png' width="160"></div>
                <img src='images/devanagari.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Detection and Recognition of Handwritten Text written in Devanagari script from documents</papertitle>
              </a>
              <br>
              <p>
                While there exists large literature to detect and recognise English text in natural scenes and documents, during the time of this study, regional languages were not very largely studied. In this project done at <a target=”_blank” href="http://www.barc.gov.in/">Bhabha Atomic Research Center, Mumbai</a>, dealt with a huge shortage of data and the nuances in the Devanagari script. Learning strategies for constrained settings like few-shot learning, transfer learning were used to develop the project. The project was implemented using Keras and Python. A great deal of OpenCV, Matplotlib and other scientific tools were also used.
              </p>
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">Code </a>
            </td>
          </tr>           
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cern.jpg' width="160"></div>
                <img src='images/cern.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Studying ways to solve challenges faced by the LHC (CERN) with Machine Learning</papertitle>
              </a>
              <br>
              <p>
                A humongous amount of data is produced by the <a target=”_blank” href="https://home.cern/science/accelerators/large-hadron-collider">LHC</a> per day. This data needs to be processed and used efficiently for further research. This study was on how Machine Learning can be implemented for particle identification, particle track reconstruction, clustering of particles based on similarity, and identifying rare decays. A study on the proposed <a target=”_blank” href="https://ship.web.cern.ch/">SHiP</a> experiment, with the scope of Machine Learning in it, was also done.
              </p>
            </td>
          </tr> 


          
        </tbody></table>
      -->
        <table style="margin-top:40px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Personal</heading>
              <p>I often like to go out visit new places and capture nature, people and moments. Besides, I like indulging in a wide variety of music. </p>
                
            </td>
          </tr>
        </tbody></table>


        </tbody></table>
        
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template Credits: <a style="text-align:center;font-size:small;" href="https://jonbarron.info/">Dr. Jon Barron</a>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
