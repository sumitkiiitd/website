<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sumit Kumar</title>
  
  <meta name="author" content="Sumit Kumar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sumit Kumar</name></br>
                Learning with machines.<br>
              </p>
              <p>I am a PhD student in <a target=”_blank” href="https://cse.iiitd.ac.in/">CSE </a> department at <a target=”_blank” href="https://iiitd.ac.in/">IIIT Delhi </a> working under <a target=”_blank” href="https://faculty.iiitd.ac.in/~rinku/">Dr. Rinku Shah</a>. My research centers on challenges and opportunities in networking for AI/ML systems. I am actively working towards simulation infrastructure for AI training and inference workloads for large models.
              </p>
              <p>
                Previously, I worked under the guidance of <a target=”_blank” href="https://jnu.ac.in/content/karan">Dr. Karan Singh</a> in the Security and Computing Laboratory, <a target=”_blank” href="https://jnu.ac.in/node">Jawaharlal Nehru University, New Delhi</a> where I have worked on the Energy Optimization of Wireless Sensor Nodes for my M.Tech degree. Earlier, I have also completed my M.Sc. in Computer Science from <a target=”_blank” href="https://www.cusb.ac.in/">Central University of South Bihar, Gaya</a>. I graduated from Magadh University with a Bachelor's degree in Computer Application. 
              </p>
              <p>
                My prior research experience has been on networking, WSN and applied machine learning.
              </p>
              <p style="text-align:center">
                <a target=”_blank” href="mailto:sumitk@iiitd.ac.in">Email</a> &nbsp/&nbsp
                <a target=”_blank” href="data/Resume_Sigcomm.pdf">CV</a> &nbsp/&nbsp
                <a target=”_blank” href="https://www.linkedin.com/in/sumit-kumaar/">Linkedin</a> &nbsp/&nbsp
                <a target=”_blank” href="https://sumitkiiitd.github.io/website/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a target=”_blank” href="images/Sumit.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Sumit_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Updates</heading>
              <p>
                <b>[Sept '25]:</b> Presented a poster on my research work at Research Innovation and Incubation Showcase Events <a target=”_blank” href="https://iiitd.ac.in/riise2025/">(RIISE)</a></br>
                <b>[Sept '25]:</b> Attended the <a target=”_blank” href="https://conferences.sigcomm.org/sigcomm/2025/">SIGCOMM 2025</a> conference in Combira, Portugal and presenetion my first short paper at SIGCOMM NAIC workshop. <a target=”_blank” href="https://dl.acm.org/doi/10.1145/3748273.3749212"> [Paper]</a>  <a target=”_blank” href="https://www.arxiv.org/abs/2508.05370"> [Arxiv]</a></br>
                <b>[Mar '25]:</b> Presented a poster on my research work at CSE Day'25 IIITD.</br>
                <b>[Jan '25]:</b> Attendent the <a target=”_blank” href="https://cse.iith.ac.in/icdcn-2025/index.html">ICDCN</a> Conference held at IIT hyderabad. <a target=”_blank” href="data/icdcn-cet.pdf"> [Certificate]</a></br>
                <b>[Dec '23]:</b> Volunteer and Participant at the <a target=”_blank” href="https://www.iiitd.ac.in/fsn/">ACM India Winter School on "Full-stack Networking (FSN)"</a>. <a target=”_blank” href="https://github.com/pnl-iiitd/acm_fsn/blob/main/Day_1_Linux_networking_basics/Dec18_handson_session.pdf"> [Presentation]</a></br>
                <b>[Oct '23]:</b> Started my Ph.D. journey under the supervision of <a target=”_blank” href="https://faculty.iiitd.ac.in/~rinku/">Dr. Rinku Shah</a>.</br>
                <b>[Mar '23]:</b> Joined as Intern at CNH Industrial in the Data Analytics team.  <a target=”_blank” href="data/Internship.pdf"> [Certificate]</a></br> 
              </p>
            </td>
          </tr>
        </tbody></table>

        <!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <script>
          function myFunction(pub_name) {
              var x = document.getElementById(pub_name);
              if (x.style.display === 'none') {
                  x.style.display = 'block';
              } else {
                  x.style.display = 'none';
              }
        }
        </script>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a target=”_blank” href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a target=”_blank” href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
              <a target=”_blank” href="https://phogzone.com/">Peter Hedman</a>,
              <a target=”_blank” href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a target=”_blank” href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
              <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a target=”_blank” href="http://jonbarron.info/mipnerf">project page</a>
              /
              <a target=”_blank” href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a target=”_blank” href="https://youtu.be/EpH175PY1A0">video</a>
              /
              <a target=”_blank” href="https://github.com/google/mipnerf">code</a>
              <p></p>
              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
            </td>
          </tr>  -->
<!--
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/adverb.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/adverb.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.html">
              <papertitle>AdVerb: Visually Guided Audio Dereverberation</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://schowdhury671.github.io/">Sanjoy Chowdhury</a>, 
              <a target=”_blank” href="https://sreyan88.github.io/">Sreyan Ghosh</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://anton-jeran.github.io/antonjeran.github.io/">Anton Ratnarajah</a>,
              <a target=”_blank” href="https://utkarsh4430.github.io/">Utkarsh Tyagi</a>,
              <a target=”_blank” href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>
              <br>
              <em>ICCV</em>, 2023 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--             <a target=”_blank” href="#">Code</a>
              /
              <a target=”_blank” href="https://schowdhury671.github.io/adverb/">Website</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('iccv23_0_bib')">BibTex</a>
              <p></p>
              <p>AdVerb leverages visual cues of the environment to estimate clean audio from reverberant audio.
                For instance, given a reverberant sound produced in a large hall, our model attempts to remove the 
                reverb effect to predict the anechoic or clean audio.</p>
              <div id="iccv23_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @article{chowdhury2023adverb,<br>
                    title={AdVerb: Visually Guided Audio Dereverberation},<br>
                    author={Chowdhury, Sanjoy and Ghosh, Sreyan and Subhrajyoti, Dasgupta and Ratnarajah, Anton and Tyagi, Utkarsh and Manocha, Dinesh},<br>
                    journal={ICCV},<br>
                    year={2023}<br>
                  }
              </font></div>
            </td>
          </tr>

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/unshadownet.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/unshadownet.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://ieeexplore.ieee.org/document/10217820">
              <papertitle>UnShadowNet: Illumination Critic Guided Contrastive Learning for Shadow Removal</papertitle>
              </a>
              <br>
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=W8DTl_gAAAAJ&hl=en">Arindam Das</a>, 
              <a target=”_blank” href="https://scholar.google.com/citations?user=z0a8rsYAAAAJ&hl=en">Senthil Yogamani</a>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=aH6w8VcAAAAJ&hl=en">Ciarán Eising</a>,
              <a target=”_blank” href="https://scholar.google.com/citations?user=HTfERCsAAAAJ&hl=en">Andrei Bursuc</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>IEEE Access</em> 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--              <a target=”_blank” href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10217820">Paper</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('ieeeaccess_0_bib')">BibTex</a>
              <p></p>
              <p>Shadow removal is a hard task given the challenges associated with it, one of them being unavailabilty of paired 
                labelled data. We propose a weakly supervised, illumination critic guided method using contrastive learning for 
                efficiently removing shadows.
              </p>
              <div id="ieeeaccess_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                @article{dasgupta2023unshadownet,</br>
                  title={UnShadowNet: Illumination Critic Guided Contrastive Learning For Shadow Removal},</br>
                  author={Dasgupta, Subhrajyoti and Das, Arindam and Yogamani, Senthil and Das, Sudip and Eising, Ciar{\'a}n and Bursuc, Andrei and Bhattacharya, Ujjwal},</br>
                  journal={IEEE Access},</br>
                  year={2023},</br>
                  publisher={IEEE}</br>
                }
              </font></div>
            </td>
          </tr>
          
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/audvisum.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/audvisum.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">
              <papertitle>AudViSum: Self-Supervised Deep Reinforcement Learning for diverse Audio-Visual Summary generation</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>, 
              <a target=”_blank” href="https://scholar.google.com/citations?user=FcEMgBgAAAAJ&hl=en">Aditya P. Patra</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>BMVC</em>, 2021 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
<!--              <a target=”_blank” href="https://github.com/schowdhury671/AudViSum">Code</a>
              /
              <a target=”_blank” href="https://www.youtube.com/watch?v=Hier-zMWcc0">Presentation</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('bmvc21_0_bib')">BibTex</a>
              <p></p>
              <p>Generating representative and diverse audio-visual summaries by exploiting both the audio and visual modalities, unlike prior works. Also presented a new dataset on TVSum and OVP with audio and visual annotations.</p>
              <div id="bmvc21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @inproceedings{chowdhury2021audvisum, </br>
                    title={AudViSum: Self-Supervised Deep Reinforcement Learning for Diverse Audio-Visual Summary Generation.}, </br>
                    author={Chowdhury, Sanjoy and Patra, Aditya P. and Dasgupta, Subhrajyoti and Bhattacharya, Ujjwal},</br>
                    booktitle={BMVC},</br>
                    <!-- pages={245},</br> -->
<!--                    year={2021}</br>
                  }
              </font></div>
            </td>
          </tr>



          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/icip_21.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/icip_21.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }
                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").show();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://ieeexplore.ieee.org/document/9506019">
                <papertitle>Listen to the Pixels</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>ICIP</em>, 2021
              <br>
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/audio_visual_cosegmentation">Code</a> /
              <a target=”_blank” href="https://www.youtube.com/watch?v=xUwzSQaQ9oQ">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icip21_0_bib')">BibTex</a>
              <p></p>
              <p>Audio-visual co-segmentation and sound source separation using a novel multimodal fusion mechanism, also addressing partially occluded sound source separation and co-segmentation for multiple but similar sound sources.
              </p>
              <div id="icip21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9506019,</br>
                    author={Chowdhury, Sanjoy and Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},</br>
                    booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, </br>
                    title={Listen To The Pixels}, </br>
                    year={2021},</br>
                    pages={2568-2572},</br>
                    doi={10.1109/ICIP42928.2021.9506019}</br>
                  }
              </font></div>
            </td>
          </tr> 


          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cardiogan.png' width="160"></div>
                <img src='images/cardiogan.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").fadeToggle();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9412905">
                <papertitle>CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms</papertitle>
              </a>
              <br>
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
              <em>ICPR</em>, 2020
              <br>
              <a target=”_blank” href="https://www.youtube.com/watch?v=BmOG9IMXFUU">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icpr20_0_bib')">BibTex</a>
              <p></p>
              <p>
                Generating synthetic ECGs, for easy sharing without risk of privacy breach, using an Attention-based Generative Adversarial Network.
              </p>
              <div id="icpr20_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:   #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9412905,<br> 
                    author={Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},<br>
                    booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, <br>
                    title={CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms}, <br>
                    year={2021},<br>
                    pages={3193-3200},<br>
                    doi={10.1109/ICPR48806.2021.9412905}<br>
                }
            </td>
          </tr> 


          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/devanagari.png' width="160"></div>
                <img src='images/devanagari.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Detection and Recognition of Handwritten Text written in Devanagari script from documents</papertitle>
              </a>
              <br>
              <p>
                While there exists large literature to detect and recognise English text in natural scenes and documents, during the time of this study, regional languages were not very largely studied. In this project done at <a target=”_blank” href="http://www.barc.gov.in/">Bhabha Atomic Research Center, Mumbai</a>, dealt with a huge shortage of data and the nuances in the Devanagari script. Learning strategies for constrained settings like few-shot learning, transfer learning were used to develop the project. The project was implemented using Keras and Python. A great deal of OpenCV, Matplotlib and other scientific tools were also used.
              </p>
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">Code </a>
            </td>
          </tr>           
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cern.jpg' width="160"></div>
                <img src='images/cern.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Studying ways to solve challenges faced by the LHC (CERN) with Machine Learning</papertitle>
              </a>
              <br>
              <p>
                A humongous amount of data is produced by the <a target=”_blank” href="https://home.cern/science/accelerators/large-hadron-collider">LHC</a> per day. This data needs to be processed and used efficiently for further research. This study was on how Machine Learning can be implemented for particle identification, particle track reconstruction, clustering of particles based on similarity, and identifying rare decays. A study on the proposed <a target=”_blank” href="https://ship.web.cern.ch/">SHiP</a> experiment, with the scope of Machine Learning in it, was also done.
              </p>
            </td>
          </tr> 


          
        </tbody></table>
      -->
        <table style="margin-top:40px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Personal</heading>
              <p>I often like to go out visit new places and capture nature, people and moments. Besides, I like indulging in a wide variety of music. </p>
                
            </td>
          </tr>
        </tbody></table>


        </tbody></table>
        
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template Credits: <a style="text-align:center;font-size:small;" href="https://jonbarron.info/">Dr. Jon Barron</a>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
